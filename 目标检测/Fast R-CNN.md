# Fast R-CNN

## before

挑战：如何产生候选框，候选框太粗略

- **RCNN：**选择性搜索繁琐，2000个区域提议串行输入CNN重叠部分导致重复计算，多步流水线非端到端，解耦分类回归任务切断了其联系，时间空间开销大，速度慢

- **SPPnet：**对整图提特征，在特征图上截取候选框并做不同尺寸的最大池化，拼接最终的特征向量（对每个 ROI 做 **SPP**金字塔池化），显著加速，但仍为多阶段、SVM、回归边界，特征向量需写入磁盘，调优算法不能更新SPP层之前的卷积层（冻结CNN，离线存储特征图），准确率受限

    ![截屏2025-09-27 09.39.43](../assets/%E6%88%AA%E5%B1%8F2025-09-27%2009.39.43.png)

**Fast R-CNN 的核心目标**：在**整图上共享卷积特征** 的同时，实现 **端到端** 训练，并拿回对卷积层的完整微调能力



---



## 论文结构

1. **引言**：动机与贡献概述，相关研究如R-CNN、SPPnet
2. **网络架构和训练方法**：整图卷积 + 两头结构、RoI Pooling、预训练网络、分层采样、端到端微调、多任务损失、mini-batch采样、roi的反传、step decay学习率调度、单尺度训练+单尺度测试、截断SVD训练
3. **实验结果**：PASCAL VOC 等数据集上的速度与精度
4. **消融实验**：发现多任务有用（取代分段训练），单尺度够用（多尺度仅好一点但慢），大训练集有用，softmax能用（取代SVM），proposal不是越多越好
5. 小结

## 创新点

- **一次卷积，RoI 共享，可端到端**：摒弃了 R-CNN 的“每框一遍 CNN”，相比 SPPnet能**反传到卷积层**
- 把spp多层金字塔简化成单层固定bins（7*7），降低了实现复杂度
- **多任务联合训练**：分类与定位在**统一损失**下协同优化，优于 “先分类再独立回归” 的割裂流程
- **丢掉 SVM 与离线缓存**：用 softmax 直接训练分类器，简化流水线，训练/部署更干净
- **测试加速技巧**：提供 **FC 层 SVD 低秩分解** 的推理加速方案

## 局限

- **仍依赖外部 proposals**（选择性搜索）：成为速度瓶颈与性能上限约束
- **RoI Pooling 的量化对齐误差**（bin 边界取整），在小物体/精定位上有影响（后被 **RoI Align** 解决）
- 仍为二阶段（区域提议+分类精修），**端到端时延**与吞吐仍处劣势（和一阶段算法相比）
- 类别特定回归器在长尾类别或类数极多时可能不稳（数据稀疏）



---



## 基本原理

![截屏2025-09-27 14.57.36](../assets/%E6%88%AA%E5%B1%8F2025-09-27%2014.57.36.png)

![fast-rcnn](../assets/fast-rcnn.svg)

1. **选择性搜索**：在**原图**上生成候选框（2000个），其位置和大小均**基于原图坐标**，做**随机水平翻转**（需同步翻转坐标，垂直翻转无现实合理性不考虑）

2. 共享主干**CNN **：**（核心改进）**整张原图送进CNN，得到一张共享的 **feature map**（特征图，已**缩小分辨率**），使用有5个最大池化层和5到13个不等的卷积层的三种网络进行预训练：CaffeNet，VGG_CNN_M_1024，VGG-16

    - 用RoI pooling layer取代网络的最后一个池化层
    - 最后一个FC层和softmax被替换成fast R-CNN框架图介绍的两个并列层
    - 证明**单尺度可获得尺度不变性**（模型对目标尺寸变化的鲁棒性）且更简洁，输入的短边统一缩放到600像素，长边不超过1000像素，CNN在这个尺度下自己学会识别大小物体

3. 采样策略：分层采样（两级抽样）

    - 图像级采样：每次随机采样一个mini-batch，包含N 张图像
    - 候选框级采样：正负比1:3，从每张图像的约 2000 个候选框中采样64个，正样本为 IoU ≥ 0.5，负样本0.1 < IoU < 0.5，IoU < 0.1忽略

    大幅共享特征图，强制增加batch内的**样本多样性**，提升泛化能力，为BatchNorm提供更丰富的统计信息，避免过拟合

4. **ROI 与 Feature Map 的映射**：

    - **RoI区域**：region of interest，将SS得到的候选框坐标根据 CNN 的下采样比例映射到 **feature map** 上，**形状大小不固定**，保留了候选目标的语义特征
    - **RoI Pooling**：把不定大小的RoI区域**切分成固定数量**的 bins，每个候选框对应的特征区域被池化成一个**固定大小的特征张量**，送进后续的全连接层做分类和回归

5. 分支头：**分类分支**softmax 输出 K+1类，**回归分支**为每一类学习一组边框回归参数（类别特定回归器）

6. **多任务联合损失**：分类和定位在 **同一网络、同一目标** 下共同优化

    ```math
    L(p,u,t^u,v) = L_{cls}(p,u)+\lambda[u \ge 1]L_{loc}(t^u,v)
    ```

    其中：

    - $L_{cls}(p,u) = -\log p_u$，交叉熵，u为真实类别（0为背景）
    - $L_{loc}(t^u,v) = \sum_{i \in \{x,y,w,h\}}smooth_{L_1}(t^u_i-v_i)$，$\lambda$控制两种损失的平衡（论文中为1），指示函数背景类时为0（只计算分类损失）
    - $smooth_{L_1}(x) =
        \begin{cases}
        0.5x^2 & if |x| < 1\\
        |x|-0.5 & otherwise
        \end{cases}$，小误差时零点附近梯度连续可导，收敛平滑稳定，大梯度时被限制为1避免爆炸，相比L2损失对异常值不敏感

7. **端到端微调**：解决了 SPPnet 的反传问题，**RoI Pooling 可微**（对池化前的特征做 max 的反向路由）：

    - 池化本身可微，但**坐标映射的取整操作破坏了端到端的可微性**，且每个RoI可能具有非常大的感受野，训练速度慢，SPP放弃端到端训练采用近似梯度，Fast R-CNN**忽略取整造成的微小误差**，Mask R-CNN使用双线性插值彻底解决此问题

    - 前向传播时：$y_{rj} = x_{i^*(r,j)}$，即第r个RoI的第j个像素来自最大池化时选出的那个点的坐标

    - 反传时：

        ```math
        \frac{\partial L}{\partial x_i} = \sum_r \sum_j[i=i^*(r,j)]\frac{\partial L}{\partial y_{rj}}
        ```

        **只有被选中的点才累积梯度**，$\sum_j$同一输入位置可能被同一RoI的多个输出单元选中，需累加，$\sum_r$同一输出位置可能被不同RoI的不同输出单元选中，需累加，使得大部分位置梯度为0，训练高效
        
    - **部分微调：**前两层冻结，不需要从最前面的卷积层开始，只更新中高层，因为低层学习的是通用的边缘、纹理等低级特征，不同任务上变化不大，而中高层更贴近任务，如检测中的物体形状、语义模式

8. SGD超参数：step decay学习率调度，momentum=0.9，权重衰减5e-4，两fc层间dropout

9. **推理**：发现fc层占用前向计算时间，推理用截断SVD（取前k个最大的奇异值及奇异向量，训练不用），再用NMS

    - 大部分能量集中在前几个奇异值上，小奇异值主要对应噪声，截断可压缩存储并提升泛化能力





