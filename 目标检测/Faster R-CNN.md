# Faster R-CNN

## 论文结构

1. **引言**：候选区域方法的速度瓶颈，提出RPN，实现实时检测
2. **相关工作**：对比传统滑窗检测器与基于候选区域的检测器，总结R-CNN、SPPnet、Fast R-CNN等前期工作
3. **网络架构**：共享卷积特征 + RPN + RoI Pooling + Fast R-CNN
    - **区域建议网络（RPN）**：Anchor，多尺度，损失函数，超参数
    - 训练细节、方案：交替训练
4. **实验**：在PASCAL VOC、MS COCO上与Fast R-CNN、R-CNN等方法对比，消融实验
5. **结论**：总结贡献与未来方向

## 创新点

- **端到端的候选区域生成**：摒弃了传统的启发式或外部候选区域方法，提出区域建议网络**RPN**，将原本由独立算法生成候选区域的步骤整合进深度神经网络中，使得**检测框生成与分类/回归共同学习**，大幅提升检测速度和精度，实现端到端目标检测流程

    > Faster R-CNN用深度网络统一了候选区域生成和检测，使目标检测真正迈入高效、端到端的时代

- **Anchor机制**：通过多尺度多长宽比的锚框处理不同目标尺寸和形状，避免了金字塔等耗时的多尺度处理

- **联合训练策略**：交替训练RPN和检测器，使特征不断优化以兼顾候选区域和分类任务

## 局限

- **速度仍受限**：仍为两阶段流程，比单阶段检测器慢，且需较多计算资源，对实时视频处理不友好
- **Anchor机制的超参数敏感性**：Anchor尺寸和比例**需人工设计**，处理极端目标（超大或超小）时不够灵活
- **RoI Pooling的量化误差**：RoI Pooling引入空间量化误差，后续Mask R-CNN提出RoI Align进行修正
- **小目标检测能力有限**：Backbone输出特征图分辨率低，小物体往往在卷积下被模糊
- **难以直接适用于移动端**：模型较大，推理速度慢，难以部署在资源受限设备上



------



## 基本原理

![faster-rcnn](../assets/faster-rcnn.svg)

Faster R-CNN由**四个主要模块**构成：

1. **特征提取（Backbone）：**使用**预训练**的CNN提取图像特征，输出的特征图被RPN和Fast R-CNN**共享**
2. **区域建议网络（RPN）：**
    - 步骤：
        - 在共享特征图上用**滑动窗口（3×3卷积）**扫描，卷积的通道数为c，即特征图中每个单元均得到长度为c的新特征
        - 以每个像素为中心，生成**k个锚框**，常用k=9（3个尺度×3个长宽比）
        - 分类：用1*1卷积将c维特征映射为9\*2维输出（即9个锚框\*2类得分）
        - 回归：并行另一个1\*1卷积，输出9\*4维（即9个锚框\*4个坐标相对偏移量）
        - 非极大值抑制，输出**前N个高分候选框**供Fast R-CNN使用
    - 训练目标：$L(p_i, t_i) = \frac{1}{N_{cls}}L_{cls}(p_i, p_i^*) + \lambda \frac{1}{N_{reg}} [p_i^* L_{reg}(t_i, t_i^*)]$，$p_i$ 预测的目标概率，$p_i^*$真实标签（1表示前景），$t_i$预测框参数，$t_i^*$真实框参数，归一**非必需**可简化
3. **RoI Pooling：**将RPN输出的候选框投影回共享特征图，通过RoI Pooling将不同大小的候选框特征映射为固定大小（如7×7）的张量
4. **Fast R-CNN检测头：**输入RoI特征进行两分支预测，目标类别+边框回归













实验对比中关于**召回率**和**IoU**的分析：

- Faster R-CNN之前生成候选框算法的目标为**高召回率**（哪怕生成很多错误的框），慢，CPU运算，成为整个检测流程的瓶颈
- **RPN**为**全卷积网络**，与主检测网络**共享特征**，可**端到端训练**，可理解为一种数据驱动的软注意力，网络自动学习到哪些位置更可能有目标







RPN 更像是**“稀疏的区域选择”**，而注意力机制通常是**“连续的特征加权”



论文中关于召回率和IoU的论述主要想说明以下几点：

- **在相同的IoU阈值下，RPN的召回率远高于传统方法**：
    - **召回率**衡量的是找得全不全，`召回率 = 检测出的真实物体数 / 图中所有的真实物体数`。召回率越高，说明漏检越少。
    - **IoU阈值**判断一个候选框是否“正确”的标准，如果一个候选框与真实框的IoU大于这个阈值，就算它“命中”了一个真实物体
    - **实验设计**：论文固定一个IoU阈值（比如0.5或0.7），然后比较RPN和Selective Search在生成不同数量（如100, 1000, 2000个）的候选框时，各自的召回率是多少
    - **结论**：**RPN的召回率曲线远高于Selective Search**，意味着用RPN生成300个候选框，其召回率可能比Selective Search生成2000个候选框还要高！这直接证明了RPN生成候选框的**质量极高**，用更少的框就能覆盖图像中几乎所有的真实物体
- **RPN对IoU阈值的变化不敏感，表现出更强的鲁棒性**
    - **实验设计**：固定候选框的数量（比如2000个），然后观察随着IoU阈值的提高（从0.5到0.8），RPN和Selective Search的召回率如何下降
    - **结论**：当IoU阈值提高时（意味着对候选框的定位精度要求更严格），Selective Search的召回率会**急剧下降**。而RPN的召回率下降则**平缓得多**
    - **说明**RPN生成的候选框不仅“框住了”物体，而且**框得异常精准**（与真实物体的重叠度非常高）。即使我们用很高的定位标准（高IoU阈值）去要求它，它依然能保持不错的召回率。这对于后续检测头进行边界框回归精修是非常有利的起点。

### 4. 为什么这个论述如此重要？

这个比较的意义在于：

1. **证明了RPN的有效性**：它不是一个拍脑袋想出来的结构，而是在**核心指标上全面碾压**了经过多年优化的传统方法（Selective Search）。
2. **解释了Faster R-CNN速度快的根本原因**：因为RPN可以用**少得多的候选框数量**（论文中常用300个）就达到甚至超过传统方法2000个框的召回率。后续的分类网络只需要处理300个框，而不是2000个，速度自然大大提升。
3. **奠定了“一体化”检测框架的基础**：RPN的成功证明了区域提议这个任务完全可以由神经网络来完成，并且与检测网络共享特征，从而实现端到端训练。这为后续更多的一阶段、两阶段检测器铺平了道路。



这是个非常经典也非常容易混淆的问题 👍，我们来仔细拆开看。

------

## 1. 问题重述

- RPN 是一个**二分类器**：判断一个候选框（anchor）是**前景（object）\**还是\**背景（not object）**。
- 直觉上，二分类器只需要输出 2 个分数（例如 [前景, 背景]）。
- 但是在 Faster R-CNN 的论文和代码中，RPN 的分类层（`cls layer`）输出的是 **2k 个分数**。
- 这里的 ( k ) 是每个滑动窗口位置（spatial location）上生成的 **anchor 数目**（例如 9 个）。

问题是：

> 为什么是 **2k** 而不是 **2** ？

------

## 2. RPN 的工作方式回顾

RPN 的前向传播大致流程：

1. 对 backbone（如 VGG16/ResNet）的特征图 ( F ) 做一次 3×3 卷积（称为“sliding window”），得到中间特征 ( f(x,y) )。
2. 对于特征图上的每一个空间位置 ((x,y))，定义 ( k ) 个 anchor（不同尺度和长宽比）。
3. 对每个 anchor，我们需要预测：
    - 它是前景还是背景（**二分类**）
    - 它的边框回归参数（4 个数）

因此，RPN 的预测是**dense prediction**：每个位置都会有多组预测。

------

## 3. 分类分支的输出

在每个滑动窗口位置上，有 ( k ) 个 anchor，
每个 anchor 需要输出 2 个数（前景分数 + 背景分数）：

[
\text{输出维度} = k \times 2 = 2k
]

如果用代码表示（PyTorch 伪代码）：

```python
cls_layer = nn.Conv2d(in_channels=512, out_channels=2*k, kernel_size=1)
```

- 输出的张量维度是 `[N, 2k, H, W]`
    - ( N )：batch size
    - ( H, W )：特征图空间尺寸
    - ( 2k )：每个位置对应的分类输出

------

## 4. 为什么不是只输出 k 个数？

因为：

- 训练时通常使用**交叉熵损失（softmax over 2 classes）**。
- 对于每个 anchor，我们需要同时得到“前景”的概率和“背景”的概率。
- softmax 期望输入一个 **长度为2的向量** 来计算二分类概率。

所以模型必须为每个 anchor 预测出两个分数（logits），再用 softmax 得到概率。

> 如果只输出 k 个数，就只能表示“前景概率”，还缺少背景概率，不能直接用 softmax 计算交叉熵。

------

## 5. 换一种直观的理解

- RPN 的分类任务可以看作是：
    **“在每个位置上的 k 个 anchor 中，每个 anchor 都是一个二分类问题。”**
- 如果我们把整张特征图所有位置和 anchor 展平，RPN 相当于要同时预测 ( H \times W \times k ) 个二分类问题。
- 二分类问题的输出是 2 维，所以总输出就是 ( H \times W \times 2k )。

------

## 6. 边框回归分支对比

- 对于回归分支，每个 anchor 只需要预测 4 个边框参数（dx, dy, dw, dh）。
- 因此回归分支输出是 **4k** 个数，而不是 8k。

这也是为什么在 RPN 的头部通常有两个并行卷积层：

```text
cls_layer:  Conv(512 → 2k)
reg_layer:  Conv(512 → 4k)
```

------

## ✅ 总结回答

- RPN 的分类是**对每个 anchor 做二分类**。
- 每个 anchor 需要输出 [前景, 背景] 两个数。
- 每个空间位置有 ( k ) 个 anchor，因此分类层需要输出 ( 2k ) 个数。
- 这样才能用 softmax + cross-entropy 来计算每个 anchor 的二分类损失。

👉 **一句话记忆：**

> RPN cls 层输出的 2k 维向量 = k 个 anchor × 每个 anchor 的 2 类分数。



这是 Faster R-CNN 论文第 3.1 节（RPN）中的一段话，非常重要 👍。
我们来逐句拆解解释它的含义。

------

## 1. 原文逐句解释

> **“An important property of our approach is that it is translation invariant, both in terms of the anchors and the functions that compute proposals relative to the anchors.”**
> 我们的方法有一个重要性质：它是**平移不变的**，无论是锚框（anchor）的设置，还是基于 anchor 预测 proposal 的函数。

👉 意思是：
如果图像里的目标在图像中向左或向右移动，RPN 预测出的候选框也会跟着移动，不需要重新学习新的参数。

------

> **“If one translates an object in an image, the proposal should translate and the same function should be able to predict the proposal in either location.”**
> 如果把图像中的目标整体平移，proposal 也应随之平移，而且在新位置用**同样的预测函数**（即相同的卷积核和回归参数）就能得到正确的 proposal。

👉 表达的是：

- RPN 的卷积本身是平移等变（translation equivariant）的。
- 所以目标无论出现在左上角还是右下角，用相同的卷积核扫描就能产生正确的预测。
- 不需要为不同位置单独训练不同的参数。

------

> **“This translation-invariant property is guaranteed by our method.”**
> 这种平移不变性由我们的方法天然保证。

👉 因为：

- RPN 在**共享特征图上用一个 3×3 卷积核滑动**（权重在整个特征图上共享）。
- 每个位置上都有一组相同的 anchor。
- 因此相同的函数在所有空间位置上重复使用 → 保证了平移不变性。

------

> **“As a comparison, the MultiBox method [27] uses k-means to generate 800 anchors, which are not translation invariant.”**
> 相比之下，MultiBox 方法用 k-means 在训练集上聚类得到 800 个先验框，这些 anchor **不是平移不变的**。

👉 MultiBox 的 anchor 是一组**固定的、全局坐标的先验框**（例如集中在图像中心、长宽比例各异），
它们并不是在每个滑窗位置上重复出现。

------

> **“So MultiBox does not guarantee that the same proposal is generated if an object is translated.”**
> 因此 MultiBox **不能保证**当目标平移到图像的其他位置时，仍然能由相同的 proposal 预测函数产生相应的候选框。

👉 换句话说：

- MultiBox 学到的是一组与图像位置绑定的检测头。
- 目标换了位置，网络可能无法用同样的检测头预测出同样的候选框 → 缺乏平移等变性。

------

## 2. 核心概念：平移不变 / 平移等变

- **卷积神经网络的平移等变（translation equivariance）：**
    如果输入图像平移，卷积特征图也会相应平移。
- **平移不变的 proposal 生成：**
    在 RPN 中，anchor 是按照规则网格平铺的，每个网格位置共享同一组参数的分类和回归器。
    因此目标移动后，提案也会跟着移动。
- **MultiBox 缺乏这一性质：**
    因为其 anchor 是预定义的全局位置 + 尺度集合，不随目标平移而平移。

------

## 3. 用图示来理解

**RPN：**

```
特征图上每个格点都有相同的一组 anchor：
[位置(x,y)] → anchor1, anchor2, anchor3...
           → 同样的卷积核预测前景/背景和回归
目标平移 → 使用相同的函数在新的位置产生新的 proposal
```

**MultiBox：**

```
固定 800 个 anchor，位置是全局性的（例如图像中心偏上、偏下...）
目标平移 → 原来的 anchor 可能不再对准目标 → 需要不同检测头
```

------

## 4. 总结性解释

这段话的本质是在强调：

- RPN 的 **卷积 + 平铺式 anchor** 设计，使得 proposal 预测具有 **平移等变性**。
- 目标移动时，只要提取到的局部特征相同，预测函数就能在新位置得到同样的结果。
- MultiBox 这样的全局 anchor 不具备这种性质，因此鲁棒性较差。

👉 一句话总结：

> **RPN 的 anchor 在特征图上规则平铺，预测函数参数在所有位置共享 → 保证了 proposal 的平移等变性；
> MultiBox 的 anchor 是全局固定位置的 → 不能保证平移后的目标得到同样的 proposal。**



你问得非常到点子上 👍
确实，所谓“平铺式（tiled） anchor”看起来就像**在特征图的每个空间位置都放一组先验框**。
这听起来跟“卷积天然具有平移等变性”很像，所以要搞清楚论文为什么特地强调这一点。

我们分三步来解释：

------

## 1. 什么是“平铺式 anchor”

在 Faster R-CNN 里：

- 有一张共享的特征图 ( F(x,y) )，比如尺寸是 (H \times W)。
- 在特征图上**每个位置（cell）**都定义 (k) 个 anchor（一般是不同尺度和宽高比）。
- 这样一来，总共有 (H \times W \times k) 个 anchor。
- 网络用**相同的一套卷积参数**（通常是一个 3×3 conv + 1×1 conv head）在每个位置上预测：
    - 分类分数（前景/背景）
    - 回归修正量（dx, dy, dw, dh）

“平铺式”就指的是——**这 (k) 个 anchor 模式（比如 3 种尺度 × 3 种长宽比）在整个特征图上以网格的方式重复出现**，没有任何位置特异性。

> 📦 类比：就像在一张网格上，每个格点都放着一叠相同样式的“候选框模板”。

------

## 2. 平移等变性来自两方面

你说得没错：**卷积本身是平移等变的**，这是基础条件。
但要保证**proposal 也随目标平移而平移**，还需要 **anchor 的布置**。

- 如果 anchor 是规则平铺的（每个位置相同的一组模板），
    那么目标向右平移 5 个像素 → 也会对应到特征图右边 5 个像素处的相同 anchor 集合。
    而由于卷积核共享权重 → 预测函数在这些 anchor 上也相同 → proposal 平移。
- 如果 anchor 是**不规则、与位置绑定**的（比如只在中心放大框，边缘放小框），
    那么目标平移后，很可能对应不到原来类型的 anchor，预测函数也就不一样，无法保证提案随目标平移。

👉 所以，**卷积等变 + 平铺 anchor** 才能形成完整的平移等变的 proposal 机制。

------

## 3. 为什么论文要特别提

主要是为了与当时流行的 **MultiBox / Selective Search / EdgeBoxes** 等非卷积式方法作对比。

- **传统方法（如 MultiBox）**
    - 先用 k-means 在数据集上聚类出一组全局 anchor（例如 800 个）。
    - 每个 anchor 的位置和尺度是固定的，不会在整幅图上平移。
    - 预测头通常也是和某个 anchor 绑定的，全连接层为每个 anchor 学不同的参数。
    - → 如果目标移到别的位置，可能就没有合适的 anchor 响应。
- **RPN**
    - 用卷积在整幅特征图上**共享预测函数**。
    - anchor 在每个位置都一样，随特征图“平铺”。
    - → 保证同一目标无论出现在图像哪里，proposal 生成方式都相同。

因此论文特意强调 **translation invariant** 这个性质，以突出 RPN 相比老方法更符合 CNN 的“局部平移等变”特性。

------

## ✅ 总结回答

- “平铺式 anchor”指的是：在特征图上每个位置都放相同的一组 anchor 模板（规则网格）。
- 平移等变性不仅来自卷积，还需要 anchor 本身在空间上规则分布。
- 论文单独提出这一点，是为了与早期候选框生成方法（如 MultiBox 的全局不规则 anchor）对比，说明 RPN 能自然利用卷积网络的平移等变性。

👉 换句话说：

> CNN 提供了位置共享的计算，
> 规则平铺 anchor 提供了位置共享的先验框，
> 二者结合才实现了 RPN 的“目标平移 → proposal 也平移”的平移等变性。
