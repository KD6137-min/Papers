# Faster R-CNN

![faster-rcnn](../assets/faster-rcnn.svg)



提出**区域建议网络（Region Proposal Network, RPN）**，将原本由独立算法生成候选区域的步骤整合进深度神经网络中，使得**检测框生成与分类/回归共同学习**，大幅提升检测速度和精度，实现**端到端（End-to-End）**目标检测流程

> Faster R-CNN用深度网络统一了候选区域生成和检测，使目标检测真正迈入高效、端到端的时代



---



## 论文结构

1. **引言**：候选区域方法的速度瓶颈，提出RPN，实现实时检测
2. **相关工作**：对比传统滑窗检测器与基于候选区域的检测器，总结R-CNN、SPPnet、Fast R-CNN等前期工作
3. **网络架构**：共享卷积特征 + RPN + RoI Pooling + Fast R-CNN，解释RPN与检测网络的联合训练
4. **区域建议网络（RPN）**：锚框（Anchor）、二分类目标、边框回归，讨论多尺度、多长宽比设计
5. **实验**：在PASCAL VOC、MS COCO上与Fast R-CNN、R-CNN等方法对比，消融实验
6. **结论**：总结贡献与未来方向

## 创新点

- **端到端的候选区域生成**：摒弃了传统的启发式或外部候选区域方法，提出RPN，与检测器共享特征，实现端到端学习，基本实现接近实时的检测
- **Anchor机制**：通过多尺度多长宽比的锚框处理不同目标尺寸和形状，避免了图像金字塔等耗时的多尺度处理
- **特征共享**：检测器与RPN使用同一卷积特征图，大幅提升效率
- **联合训练策略**：交替训练RPN和检测器，使特征不断优化以兼顾候选区域和分类任务

## 局限

- **速度仍受限**：仍为两阶段流程，比单阶段检测器慢，且需较多计算资源，对实时视频处理不友好
- **Anchor机制的超参数敏感性**：Anchor尺寸和比例需人工设计，在处理极端目标（超大或超小）时不够灵活
- **RoI Pooling的量化误差**：RoI Pooling引入空间量化误差，后续Mask R-CNN提出RoI Align进行修正
- **小目标检测能力有限**：Backbone输出特征图分辨率低，小物体往往在卷积下被模糊
- **难以直接适用于移动端**：模型较大，推理速度慢，难以部署在资源受限设备上



------



## 基本原理

Faster R-CNN由**四个主要模块**构成：

1. **特征提取（Backbone）：**使用预训练的CNN提取图像特征，输出的特征图被RPN和Fast R-CNN共享
2. **区域建议网络（RPN）：**在共享特征图上用**滑动窗口（3×3卷积）**扫描，在每个位置上生成**k个锚框**，常用k=9（3个尺度×3个长宽比），对每个锚框预测：是否包含目标（前景/背景二分类）+ 四个边框回归参数（dx, dy, dw, dh）
    - 训练目标：$L(p_i, t_i) = L_{cls}(p_i, p_i^*) + \lambda [p_i^* L_{reg}(t_i, t_i^*)]$，$p_i$ 预测的目标概率，$p_i^*$真实标签（1表示前景），$t_i$预测框参数，$t_i^*$真实框参数
    - 输出**前N个高分候选框**供Fast R-CNN使用
3. **RoI Pooling：**将RPN输出的候选框投影回共享特征图，通过RoI Pooling将不同大小的候选框特征映射为固定大小（如7×7）的张量
4. **Fast R-CNN检测头：**输入RoI特征进行两分支预测，目标类别+边框回归



区域提议网络的计算步骤：

1. 使用填充为1的$3\times 3$的卷积层变换卷积神经网络的输出，并将输出通道数记为$c$。这样，卷积神经网络为图像抽取的特征图中的**每个单元**均得到一个长度为$c$的新特征
1. 以特征图的每个像素为中心，生成多个不同大小和宽高比的锚框并标注它们
1. 使用锚框中心单元长度为$c$的特征，分别预测该锚框的二元类别（含目标还是背景）和边界框
1. 使用非极大值抑制，从预测类别为目标的预测边界框中移除相似的结果。最终输出的预测边界框即是兴趣区域汇聚层所需的提议区域



区域提议网络作为Faster R-CNN模型的一部分，和整个模型一起训练得到，即Faster R-CNN的目标函数不仅包括目标检测中的类别和边界框预测，还包括区域提议网络中锚框的二元类别和边界框预测

作为端到端训练的结果，区域提议网络能够学习到如何生成高质量的提议区域，从而在减少了从数据中学习的提议区域的数量的情况下，仍保持目标检测的精度



