# Faster R-CNN

![faster-rcnn](../assets/faster-rcnn.svg)



提出**区域建议网络（Region Proposal Network, RPN）**，将原本由独立算法生成候选区域的步骤整合进深度神经网络中，使得**检测框生成与分类/回归共同学习**，大幅提升检测速度和精度，实现**端到端（End-to-End）**目标检测流程

> Faster R-CNN用深度网络统一了候选区域生成和检测，使目标检测真正迈入高效、端到端的时代



---



## 论文结构

1. **引言**：候选区域方法的速度瓶颈，提出RPN，实现实时检测
2. **相关工作**：对比传统滑窗检测器与基于候选区域的检测器，总结R-CNN、SPPnet、Fast R-CNN等前期工作
3. **网络架构**：共享卷积特征 + RPN + RoI Pooling + Fast R-CNN，解释RPN与检测网络的联合训练
4. **区域建议网络（RPN）**：锚框（Anchor）、二分类目标、边框回归，讨论多尺度、多长宽比设计
5. **实验**：在PASCAL VOC、MS COCO上与Fast R-CNN、R-CNN等方法对比，消融实验
6. **结论**：总结贡献与未来方向

## 创新点

- **端到端的候选区域生成**：摒弃了传统的启发式或外部候选区域方法，提出RPN，与检测器共享特征，实现端到端学习，基本实现接近实时的检测
- **Anchor机制**：通过多尺度多长宽比的锚框处理不同目标尺寸和形状，避免了图像金字塔等耗时的多尺度处理
- **特征共享**：检测器与RPN使用同一卷积特征图，大幅提升效率
- **联合训练策略**：交替训练RPN和检测器，使特征不断优化以兼顾候选区域和分类任务

## 局限

- **速度仍受限**：仍为两阶段流程，比单阶段检测器慢，且需较多计算资源，对实时视频处理不友好
- **Anchor机制的超参数敏感性**：Anchor尺寸和比例需人工设计，在处理极端目标（超大或超小）时不够灵活
- **RoI Pooling的量化误差**：RoI Pooling引入空间量化误差，后续Mask R-CNN提出RoI Align进行修正
- **小目标检测能力有限**：Backbone输出特征图分辨率低，小物体往往在卷积下被模糊
- **难以直接适用于移动端**：模型较大，推理速度慢，难以部署在资源受限设备上



------



## 基本原理

Faster R-CNN由**四个主要模块**构成：

1. **特征提取（Backbone）：**使用预训练的CNN提取图像特征，输出的特征图被RPN和Fast R-CNN共享
2. **区域建议网络（RPN）：**
    - 步骤：在共享特征图上用**滑动窗口（3×3卷积）**扫描，卷积的通道数为c，即特征图中每个单元均得到长度为c的新特征，以每个像素为中心，生成**k个锚框**，常用k=9（3个尺度×3个长宽比），用每个锚框中心单元长度为c的特征，预测：该锚框是否包含目标（前景/背景二分类）+ 四个边框回归参数（dx, dy, dw, dh），再使用非极大值抑制，输出**前N个高分候选框**供Fast R-CNN使用
    - 训练目标：$L(p_i, t_i) = \frac{1}{N_{cls}}L_{cls}(p_i, p_i^*) + \lambda \frac{1}{N_{reg}} [p_i^* L_{reg}(t_i, t_i^*)]$，$p_i$ 预测的目标概率，$p_i^*$真实标签（1表示前景），$t_i$预测框参数，$t_i^*$真实框参数，归一非必需可简化
3. **RoI Pooling：**将RPN输出的候选框投影回共享特征图，通过RoI Pooling将不同大小的候选框特征映射为固定大小（如7×7）的张量
4. **Fast R-CNN检测头：**输入RoI特征进行两分支预测，目标类别+边框回归



### 实验对比

**召回率**和**IoU**

在Faster R-CNN之前，目标检测流程分两步：

1. **区域提议**：使用一种**与网络无关**的方法从图像中生成可能包含物体的候选框，这一步的目标是**高召回率**，即尽可能不漏掉任何真实物体，哪怕生成很多错误的框也没关系
2. **分类与精修**：对每一个候选框，用一个CNN模型去判断它里面是什么物体，并微调框的位置

问题在于：第一步的区域提议方法速度慢，且是CPU运算，成为整个检测流程的瓶颈

Faster R-CNN的创新在于提出了**RPN**，它是一个**全卷积网络**，与主检测网络**共享特征**，可以**端到端训练**。RPN的任务就是快速、高效地生成高质量的候选区域



论文中关于召回率和IoU的论述主要想说明以下几点：

- **在相同的IoU阈值下，RPN的召回率远高于传统方法**：
    - **召回率**衡量的是找得全不全，`召回率 = 检测出的真实物体数 / 图中所有的真实物体数`。召回率越高，说明漏检越少。
    - **IoU阈值**判断一个候选框是否“正确”的标准，如果一个候选框与真实框的IoU大于这个阈值，就算它“命中”了一个真实物体
    - **实验设计**：论文固定一个IoU阈值（比如0.5或0.7），然后比较RPN和Selective Search在生成不同数量（如100, 1000, 2000个）的候选框时，各自的召回率是多少
    - **结论**：**RPN的召回率曲线远高于Selective Search**，意味着用RPN生成300个候选框，其召回率可能比Selective Search生成2000个候选框还要高！这直接证明了RPN生成候选框的**质量极高**，用更少的框就能覆盖图像中几乎所有的真实物体
- **RPN对IoU阈值的变化不敏感，表现出更强的鲁棒性**
    - **实验设计**：固定候选框的数量（比如2000个），然后观察随着IoU阈值的提高（从0.5到0.8），RPN和Selective Search的召回率如何下降
    - **结论**：当IoU阈值提高时（意味着对候选框的定位精度要求更严格），Selective Search的召回率会**急剧下降**。而RPN的召回率下降则**平缓得多**
    - **说明**RPN生成的候选框不仅“框住了”物体，而且**框得异常精准**（与真实物体的重叠度非常高）。即使我们用很高的定位标准（高IoU阈值）去要求它，它依然能保持不错的召回率。这对于后续检测头进行边界框回归精修是非常有利的起点。

### 4. 为什么这个论述如此重要？

这个比较的意义在于：

1. **证明了RPN的有效性**：它不是一个拍脑袋想出来的结构，而是在**核心指标上全面碾压**了经过多年优化的传统方法（Selective Search）。
2. **解释了Faster R-CNN速度快的根本原因**：因为RPN可以用**少得多的候选框数量**（论文中常用300个）就达到甚至超过传统方法2000个框的召回率。后续的分类网络只需要处理300个框，而不是2000个，速度自然大大提升。
3. **奠定了“一体化”检测框架的基础**：RPN的成功证明了区域提议这个任务完全可以由神经网络来完成，并且与检测网络共享特征，从而实现端到端训练。这为后续更多的一阶段、两阶段检测器铺平了道路。
