# R-CNN

Region-based Convolutional Neural Network，区域卷积神经网络

![截屏2025-09-20 21.13.56](../assets/%E6%88%AA%E5%B1%8F2025-09-20%2021.13.56.png)

## before R-CNN

**在 R-CNN 之前**：目标检测基本依赖 **手工特征**（[HOG](相关知识.md#HOG)、DPM、SIFT 等），检测时先**生成候选框**再用 **SVM + 特征描述符**分类，效果有限

:bulb:ImageNet 2012 之后，AlexNet 展示了 CNN 在分类任务的巨大潜力

**R-CNN 的问题意识**：CNN 在分类上很强，能不能把它迁移到检测任务？

**地位：**用深度 CNN 替代手工特征的第一代检测器，**开启了深度学习目标检测的时代**，CNN 正式取代 HOG、DPM，深度学习成为检测主流，但速度太慢，只是过渡方案



---



## 基本原理：

1. **候选区域生成**：使用[**选择性搜索**](相关知识.md#选择性搜索)从输入图像中提取约2000个候选区域，**第一次计算IoU**，以0.5阈值分配标签，1:3偏向性采样
2. **特征提取**：每个候选区域被缩放到**固定尺寸**，输入**预训练**的共享的CNN（微调，前面的层设置小学习率，最后分类层替换为自己的softmax分类N+1类）提取特征，将图像转换为**高维特征向量**用于后续分类和定位
3. **分类与边界框回归**：
    - **分类**： **SVM** ，抛弃第一次计算的IoU和标签，用更严格规则**第二次计算IoU**并分配标签，困难负样本挖掘
    - **回归**：通过线性回归模型调整候选框的位置和大小，使其更精确地包围目标
4. **非极大值抑制** ：对重叠的候选框进行筛选，保留置信度最高的检测结果，去除冗余框



---



## 论文结构

1. **引言**：目标检测的难点（背景复杂、类间差异小）、动机：CNN 在分类成功，能否用于检测？
2. **方法**：Selective Search 提 proposals、共享CNN 提特征、SVM 分类、边框回归
3. **实验**：在 PASCAL VOC 上实验，和传统 DPM 对比、**消融实验**（proposal 数量、fine-tuning 的作用）
4. **结论**：大幅度提升了 mAP、CNN 特征在检测上比传统方法更强

## 创新点

1. 第一次把**CNN特征提取**应用到目标检测，替代了传统的 HOG/DPM 特征
2. 提出**Region Proposal + CNN 特征** 思路
3. 第一次把**迁移学习**用到目标检测：利用**预训练的 AlexNet** 提取图像区域特征，在检测数据集上微调，再做分类

总结：**R-CNN = proposals + CNN 特征 + SVM 分类 + 边框回归**

## 缺点

1. **速度极慢**：2000 proposals × 每个都过 CNN → 推理极慢
3. **不是真正的 end-to-end**：检测部分和分类部分分离，CNN 训练 → SVM 训练 → 边框回归器训练 → 分开优化，分阶段训练 + 分阶段反向传播



---



## 具体实现

### :o: 偏向性采样

解决极端类别不平衡问题，生成的大量区域提议中绝大多数都是**背景（Negative）**，**正样本（Positive）**极少

> 若抽样完全随机：
>
> - **模型会“偷懒”**：模型很快会发现，只要把所有东西都预测为“背景”，就能获得非常高的准确率
> - **训练低效且浪费**：大量的计算和内存被用来学习“这是背景”，正样本信息则被淹没在海量的背景样本中
>
> 因此，必须采用一种有“偏向性”的采样策略，来**人为地提高正样本在训练数据中的比例**，让模型能够有效地学习到物体的特征
>
> 负样本数量极大，随机抽样足以代表“背景”的多样性和分布，模型不需要看到所有的负样本来理解什么是背景

IoU > 0.5为正样本，学习高质量正样本学习物体的通用特征，0.5 > IoU > 0.1为负样本

采样规则：

- **正样本**：**全部保留**。因为正样本极其稀少，每一个都非常宝贵。这就是“Bias”的体现——**正样本被采样的概率是100%**
- **负样本**：随机抽取一小部分

比例固定，常用正负比1:3，保留信息基础上，大大减少数据集，保证了计算效率

### :o: 微调阶段

**共享CNN**：整个网络只存在一个CNN，但是候选框仍是逐个送进CNN，慢

- 网络学会了提取通用、强大的图像特征（如边缘、纹理、形状模式），可以很好地泛化到训练时未见过的物体外观上
- 只训练**一组参数**，使端到端的训练成为可能

**微调过程：**保留预训练网络的卷积层和全连接层，在最后加一个 **softmax 分类器**（N类 + 1个背景类），用 **交叉熵 loss** 来训练，梯度通过 softmax → 全连接层 → 卷积层反向传播，此阶段**SVM 完全不参与**

微调完成后，CNN 就变成了一个**固定的特征提取器**，所有候选框的特征被保存到磁盘，进入第二阶段，训练SVM和回归器，此时CNN权重冻结不更新

### :o: 训练SVM

SVM 是独立的二元分类器，输入 **CNN 提取的特征向量**，损失函数是 hinge loss铰链损失，训练方式是传统 SVM 求解，在**特征空间**里调整权重，不用梯度下降

#### 困难负样本挖掘

Hard Negative Mining，采样过程分阶段、有偏向，用于SVM训练

**第一步：构建样本库**

- 对每个区域提议计算其与真实标注框的IoU
- 根据IoU为其打上标签：
    - **正样本**：与真实标注框的IoU >= 0.5
    - **负样本**：与真实标注框的IoU < 0.3
    - 灰区样本：0.3 < IoU < 0.5，全程不参与SVM训练，直接丢掉

**第二步：初始训练SVM**，负样本**随机抽样**，正负比1:3，快速得到一个初始决策边界

**第三步：找出困难负样本**，用初始SVM对**所有**负样本做预测，找出那些被模型**错误地**高分识别为物体的负样本（即困难负样本），加入到初始训练集中，重新训练SVM，迭代多次，从而得到更强的分类器

### :o: 边界框回归

Bounding Box Regression，线形回归器，损失函数用L2损失（MSE）

预测**调整量**（offsets，**尺度归一化**的）

- **中心点调整**：预测中心点需要平移的量，$t_x = (G_x-P_x)/P_w,t_y = (G_y-P_y)/P_h$
- **尺度调整**：预测宽高需要缩放的量（缩放倍数为乘法值，绝对误差小框敏感大框不敏感），$t_w=log(G_w/P_w), t_h=log(G_h/P_h)$，对数尽可能消除框尺度的影响

**推理**时，用练好的回归器预测出它的调整量$t_x,t_y,t_w,t_h$，通过公式计算出最终微调后的边界框

$G:G_x = P_w \cdot t_x + P_x,G_y = P_h \cdot t_y + P_y, G_w = P_w \cdot exp(t_w),G_h=P_h \cdot exp(t^h)$



