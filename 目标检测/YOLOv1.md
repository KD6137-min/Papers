# YOLOv1

You Only Look Once，一种端到端的单阶段目标检测方法

## before YOLO

主要是**两阶段方法**：候选区域生成 → 特征提取 → 分类 + 边框回归，计算量大、速度慢

**YOLO 的问题意识**：能不能把目标检测直接建模为一个**回归问题**，从图像像素一步到位预测目标的类别与位置

**地位：**第一个真正实现 **端到端单阶段检测（one-stage）** 的框架，把检测变成了一个统一的回归问题，极大提升了速度，推动了实时目标检测的发展



---



## 基本原理

1. **统一框架**：将检测作为一个整体的**回归问题**，从图像直接预测**边界框 + 类别概率 + 置信度**
2. **网格划分**：将输入图像划分为 $S \times S$ 网格，每个网格 cell 负责预测其内部物体的边界框与类别
3. **输出内容**：
    - $B$ 个预测框，每个框包含：位置坐标 $(x,y,w,h)$ + 置信度
    - 类别条件概率 $Pr(Class|Object)$
    - 最终得分：$Pr(Class|Object) \times Confidence$
4. **端到端训练**：单一神经网络联合优化所有任务，不再需要 proposal + SVM + 边框回归等分离步骤



------



## 论文结构

1. **引言**：传统检测速度慢、流程复杂，YOLO 的动机是简化检测 → 回归建模
2. **方法**：
    - 输入图像划分为网格
    - 网络结构：GoogLeNet 风格 backbone + 输出层
    - 输出：每个 cell 的 bbox + 类别概率
    - 损失函数设计（坐标误差、置信度误差、类别误差，带权重系数）
3. **实验**：在 PASCAL VOC 上评估，速度远快于 R-CNN 系列，同时精度也有竞争力；**消融实验**展示损失设计的重要性
4. **结论**：YOLO 提供了检测的一种新范式 —— 端到端的单阶段检测，为后续 YOLO 系列奠定了基础

## 创新点

放弃**漫无目的**的锚框生成，转而使用**有组织、有纪律**的网格化锚框预测

1. 第一次把检测建模为 **端到端单一回归问题**（像素 → bbox + class）
2. 统一框架：不再依赖 proposal、SVM、分离训练，检测作为一个整体函数近似
3. 实现了**实时检测**，速度大幅提升（比 R-CNN 系列快一个数量级）

总结：**YOLOv1 = Grid 划分 + 回归预测 (位置+置信度+类别)**

## 缺点

1. **定位精度差**：尤其对小物体
2. **容易漏检**：一个 cell 只能预测有限数量目标
3. **分类与定位耦合**：最终得分是类别条件概率 × IoU，分离性不足



---



## 网络设计

**设计思路**：把“有没有目标”**单独拿出来预测**，而不是直接分类

> 只有cell中真的有目标时，才会用其后 20 个输出计算分类误差，网络学到的就是“当有目标时应该输出怎样的类别概率分布”，所以这些概率就是在“有目标”的前提下学出来的 —— 也就是条件概率
>
> 若cell中根本没有目标，则类别概率无意义，会有大量假阳性，预测质量差

**网络组成**：

1. **特征提取网络（backbone）**：GoogLeNet风格的 24 conv + 2 FC，学习图像的空间+语义特征

    ![截屏2025-09-15 19.10.38](../assets/%E6%88%AA%E5%B1%8F2025-09-15%2019.10.38.png)

    *   边缘、纹理（浅层）
    *   局部形状（中层）
    *   语义信息、物体结构（深层）

    逐步将图像压缩成一个**高维语义特征图**，每个网格 cell 对应原图的一小块区域，携带了局部感受的信息

2. **目标检测头（输出层**）：网络最后几层，负责把特征图映射到**结构化的输出空间**（目标框 + 类别 + 置信度）



---



## 实现细节

### :o: 置信度

<img src="../assets/%E6%88%AA%E5%B1%8F2025-09-15%2019.24.44.png" alt="截屏2025-09-15 19.24.44" style="zoom:50%;" />

$Pr(Object)$：Cell中包含物体的概率，有则1无则0

- $confidence = Pr(Object) * IoU^{truth}_{pred}$
  
- $class scores = Pr(Class_i|Object)$

- 最终的类别置信度（计算得出，不在网络输出中）：$ClassConfidence_i = Pr(Class_i|Object) \times Confidence$，共7\*7\*2=98 个，作为最终分数，传入NMS等后续处理

### :o: 损失函数

<img src="../assets/%E6%88%AA%E5%B1%8F2025-09-15%2019.53.09.png" alt="截屏2025-09-15 19.53.09" style="zoom:50%;" />

> $\mathbb{1}^{obj}_i$：第 i 个网格是否包含物体中心点，是1否0
>
> $\mathbb{1}^{obj}_{ij}$：第 i 个网格的第j个bbox是否负责预测目标，是1否0
>
> $\mathbb{1}^{noobj}_{ij}$：第 i 个网格的第j个bbox是否负责预测目标，是0否1

**坐标损失** = 中心点定位误差 + 宽高误差（对宽高取根号，尽量消除框尺寸影响，否则损失函数倾向于调整大框）

损失之间的权衡：用参数$\lambda_{coord}$和$\lambda_{noobj}$控制，防止不包含物体的损失值过大，压倒了包含物体的梯度

> :warning: 注意
>
> ​	**yolo v1损失函数中带hat的符号解释**：一般情况下，加hat的通常表示模型的预测值，不加的值表示真实标签（ground truth），而YOLOv1原始论文中，采用了“非主流”写法，$p_i(c)$表示预测值，模型输出，而$\hat p_i(c)$表示真实值



好的 👍，我来帮你系统介绍一下 **Darknet**。它既是一套 **神经网络框架**，也是 **YOLO 系列的骨干网络（backbone）**。

------

# 🔹 Darknet 框架

**作者：** Joseph Redmon（YOLO 作者）
**语言：** 纯 C 和 CUDA
**特点：**

- **轻量、简洁、速度快**，设计目标就是让 YOLO 能在 GPU 上实时跑。
- 不依赖 TensorFlow / PyTorch，当年是一个 **独立的深度学习框架**。
- 提供了卷积、池化、BN、激活函数（Leaky ReLU）、全连接等最常用的层。
- 模型配置用 `.cfg` 文件定义，训练用 `.weights` 文件保存。

👉 现在 YOLO 已经有 PyTorch / TensorFlow 实现，但 Darknet 框架仍然是 YOLO 的原始实现。

------

# 🔹 Darknet 作为 YOLO 的 Backbone

YOLO 作者不仅写了框架，还自己设计了 CNN 结构来替代 VGG/ResNet，叫 **Darknet**。
随着 YOLO 的发展，Darknet 也不断升级：

### 1. Darknet-19 （YOLOv2）

- 19 层卷积 + 5 层 max-pooling。
- 类似 VGG，但是更轻量。
- 在 **ImageNet** 上预训练后迁移到检测。
- 特点：引入了 **BatchNorm**，去掉了全连接层，只保留全卷积。

### 2. Darknet-53 （YOLOv3）

- 53 层卷积。
- 类似 **ResNet**（用了残差结构），但更简洁高效。
- 能兼顾精度和速度，在 COCO 上性能很好。

### 3. CSPDarknet （YOLOv4 / YOLOv5）

- 引入 **CSPNet（Cross Stage Partial Network）** 思想。
- 提升了梯度流动效率，减少计算量。
- Darknet-53 → CSPDarknet-53。

### 4. 之后的 YOLO

YOLOv5 以后，虽然不再用 C 写的 Darknet 框架，但 backbone 设计思想仍然延续（CSPDarknet, CSPDarknet-S, etc.）。

------

# 🔹 Darknet 的优势

1. **高效**：比 VGG/ResNet 更轻量，推理速度快。
2. **端到端**：为 YOLO 检测专门设计，适合回归框+分类联合任务。
3. **可移植**：C 实现，不依赖大框架，当年能在低端 GPU 实时跑。
4. **灵活**：可以直接改 `.cfg` 文件快速尝试新结构。

------

# 🔹 总结

- **Darknet 是 YOLO 作者写的 C + CUDA 深度学习框架**。
- **Darknet 也是 YOLO 系列的 backbone**，不断演进：
    - YOLOv1：简单卷积网络
    - YOLOv2：Darknet-19
    - YOLOv3：Darknet-53
    - YOLOv4+：CSPDarknet
- 设计哲学：**小而快，适合检测任务**，不走 VGG/ResNet 那种大而慢的路线。

------

要不要我帮你画一个 **“Darknet 演化树（Darknet-19 → Darknet-53 → CSPDarknet）”的图**？这样直观对比不同 YOLO 版本用的 backbone。

好，那我来帮你把 **伴随矩阵（adjugate matrix, classical adjoint）** 的几何意义梳理一下：

------

## 1. 基本定义回顾

- 对一个 n×n 矩阵 A，它的伴随矩阵 adj(A) 是 A 的余子式矩阵的转置。
- 关键关系：

A⋅adj(A)=det⁡(A)I

------

## 2. 几何意义一：体积与方向的修正

- det⁡(A) 表示线性变换 A 对单位体积的放缩因子。
- 伴随矩阵在几何上可以理解为：
    - **把 A 映射后剩余的“体积方向信息”提取出来**。
    - 当 A 不可逆时（det⁡(A)=0），adj(A) 仍然保留了部分几何信息（比如低维子空间的方向）。

例如：

- 在 3×3 情况下，adj(A) 的每一列其实是另外两列向量的叉积，代表“面元法向量”的方向和大小。

------

## 3. 几何意义二：逆矩阵的构造

- 当 det⁡(A)≠0：

A−1=1det⁡(A)adj(A)

- 也就是说，adj(A) **编码了逆变换的方向信息**，只是缺少一个“体积缩放因子” 1det⁡(A)。

------

## 4. 几何意义三：降维投影的方向

- 如果 det⁡(A)=0，矩阵 A 把空间压缩到一个低维子空间。
- adj(A) 在这种情况下通常不为零，它给出了“压缩后空间的法向量方向”。
    - 比如 3D→2D 的情形：
        - A 把体积压到一个平面。
        - adj(A) 的列向量是这个平面的法向量方向。

------

✅ **直观总结**

- det⁡(A)：体积缩放。
- adj(A)：方向修正 + 余维空间的法向量。
- A−1：缩放 + 方向修正。

------

要不要我给你画个 **3D 几何直观图（伴随矩阵和叉积的关系）**，这样更好理解？
